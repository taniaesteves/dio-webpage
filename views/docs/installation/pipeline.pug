extends ../../layout.pug

block navbar-options
    li.nav-item.active
        a.nav-link(href='/docs/installation') Installation
    li.nav-item.active
        a.nav-link(href='#installPipelineDockerCompose') Docker-Compose
    li.nav-item
        a.nav-link(href='#installPipelineKubernetes') Ansible&Kubernetes

block content

    h1#installPipeline Analysis pipeline

    br

    p To set up DIO's analysis pipeline, it is necessary to install the Elasticsearch and Kibana software and upload DIO's pre-defined dashboards. Folder <code>dio-pipeline</code> contains a docker-compose file and Ansible playbooks to create and set up DIO's pipeline automatically.


    p Start by clonning DIO's repository and accessing the <code>dio-pipeline</code> folder:

    pre
        | $ git clone https://github.com/dsrhaslab/dio.git
        | $ cd dio-pipeline


    .line

    h3#installPipelineDockerCompose > Via Docker-compose (single-node)

    p The folder <code>docker-compose</code> contains a <code>docker-compose.yml</code> file that allows configuring one container for Elasticsearch and another for Kibana. It also has a <code>.env</code> file with important variables for setting up DIO's analysis pipeline.

    ol
        li Update the necessary variables in the <code>.env</code> file according to your setup.
        li Run <code>docker-compose up</code> to start the containers.
        li Ensure that you can access and log into Kibana:
            ul
                li Access <code>http://&lt;HOST_IP&gt;:&lt;KIBANA_PORT&gt</code> in your browser;
                li Log in with:
                    ul
                        li Username: <code>"elastic"</code>;
                        li Password: <code>"&lt;ELASTIC_PASSWORD&gt;"</code>; (the elastic password defined in <code>.env</code>).

    .line

    h3#installPipelineKubernetes > Via Ansible & Kubernetes (multi-node)

    br

    p The folder <code>dio-pipeline</code> contains Ansible playbooks to automatically create and set up a Kubernetes cluster with all the required components.


    ol
        li Install Ansible and the required modules.
        pre
            |
            | $ apt install ansible
            | $ ansible-galaxy collection install ansible.posix
            | $ ansible-galaxy collection install kubernetes.core
            | $ ansible-galaxy collection install cloud.common
            | $ ansible-galaxy collection install community.general
            | $ ansible-galaxy collection install community.kubernetes

        li Update the inventory file (<code>hosts.ini</code>)  with the servers' information on where the pipeline should be installed. If more than one server is used, Kibana will be installed on the master, while Elasticsearch will run on workers'.
        ul
            li Add the <ins>master</ins> information in the group <code>"[master]"</code>
            li Add the <ins>workers</ins> information in the group <code>"[node]"</code>

        br

        details
            summary Syntax
            ul
                pre &lt;hostname&gt; ansible_host=&lt;host_ip&gt; ansible_python_interpreter='python3'

        details
            summary Example
            ul
                pre
                    | &lt;master&gt;
                    | master ansible_host=192.168.56.100 ansible_python_interpreter='python3'

                pre
                    | &lt;node&gt;
                    | worker1 ansible_host=192.168.56.101 ansible_python_interpreter='python3'
                    | worker2 ansible_host=192.168.56.102 ansible_python_interpreter='python3'

                pre
                    | &lt;kibana:children&gt;
                    | master

                pre
                    | &lt;kube_cluster:children&gt;
                    | master
                    | node

        br

        li Run the <code>run_dio_pipeline.sh</code> script to install and configure DIO's pipeline.

        pre $ bash run_dio_pipeline.sh install_dio_pipeline

        li Ensure that you can access and log into Kibana:
            ul
                li Access <code>http://&lt;MASTER_IP OR WORKER_IP&gt;:32222</code> in your browser;
                li Default credentials are:
                    ul
                        li Username: <code>"dio"</code>;
                        li Password: <code>"diopw"</code>;
                li Credentials can be changed on the <code>group_vars/kube_cluster.yml</code> file (variables <code>dio_es_user</code> and <code>dio_es_pass</code>).


    .line

    p
        | More information available at
        |
        a(href='https://github.com/dsrhaslab/dio/blob/main/dio-pipeline/README.md', target='_blank', style='color: blue;') dio-pipeline.
