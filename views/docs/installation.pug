extends ../layout.pug

block navbar-options
    li.nav-item.active
        a.nav-link(href='/') Home
    li.nav-item.active
        a.nav-link(href='#about') About
    li.nav-item
        a.nav-link(href='#Installation') Installation

block content
    h1#installation Installation

    br

    p The installation and configuration of DIO are performed in two phases:

        ol(type='i')
            li the setup and initialization of the analysis pipeline;
            li the configuration and execution of the tracer.

    .line

    h3#installPipeline Analysis pipeline

    br

    p To set up DIO's analysis pipeline, it is necessary to install the Elasticsearch and Kibana software and upload DIO's pre-defined dashboards. Folder <code>dio-pipeline</code> contains a docker-compose file and Ansible playbooks to create and set up DIO's pipeline automatically.


    p Start by clonning DIO's repository and accessing the <code>dio-pipeline</code> folder:

    pre
        | $ git clone https://github.com/dsrhaslab/dio.git
        | $ cd dio-pipeline

    br

    h5#installPipelineDockerCompose > Via Docker-compose (single-node)

    p The folder <code>docker-compose</code> contains a <code>docker-compose.yml</code> file that allows configuring one container for Elasticsearch and another for Kibana. It also has a <code>.env</code> file with important variables for setting up DIO's analysis pipeline.

    ol
        li Update the necessary variables in the <code>.env</code> file according to your setup.
        li Run <code>docker-compose up</code> to start the containers.
        li Ensure that you can access and log into Kibana:
            ul
                li Access <code>http://&lt;HOST_IP&gt;:&lt;KIBANA_PORT&gt</code> in your browser;
                li Log in with:
                    ul
                        li Username: <code>"elastic"</code>;
                        li Password: <code>"&lt;ELASTIC_PASSWORD&gt;"</code>; (the elastic password defined in <code>.env</code>).

    br

    h5#installPipelineKubernetes > Via Ansible & Kubernetes (multi-node)

    br

    p The folder <code>dio-pipeline</code> contains Ansible playbooks to automatically create and set up a Kubernetes cluster with all the required components.


    ol
        li Install Ansible and the required modules.
        pre
            |
            | $ apt install ansible
            | $ ansible-galaxy collection install ansible.posix
            | $ ansible-galaxy collection install kubernetes.core
            | $ ansible-galaxy collection install cloud.common
            | $ ansible-galaxy collection install community.general
            | $ ansible-galaxy collection install community.kubernetes

        li Update the inventory file (<code>hosts.ini</code>)  with the servers' information on where the pipeline should be installed. If more than one server is used, Kibana will be installed on the master, while Elasticsearch will run on workers'.
        ul
            li Add the <ins>master</ins> information in the group <code>"[master]"</code>
            li Add the <ins>workers</ins> information in the group <code>"[node]"</code>

        br

        details
            summary Syntax
            ul
                pre &lt;hostname&gt; ansible_host=&lt;host_ip&gt; ansible_python_interpreter='python3'

        details
            summary Example
            ul
                pre
                    | &lt;master&gt;
                    | master ansible_host=192.168.56.100 ansible_python_interpreter='python3'

                pre
                    | &lt;node&gt;
                    | worker1 ansible_host=192.168.56.101 ansible_python_interpreter='python3'
                    | worker2 ansible_host=192.168.56.102 ansible_python_interpreter='python3'

                pre
                    | &lt;kibana:children&gt;
                    | master

                pre
                    | &lt;kube_cluster:children&gt;
                    | master
                    | node

        br

        li Run the <code>run_dio_pipeline.sh</code> script to install and configure DIO's pipeline.

        pre $ bash run_dio_pipeline.sh install_dio_pipeline

        li Ensure that you can access and log into Kibana:
            ul
                li Access <code>http://&lt;MASTER_IP OR WORKER_IP&gt;:32222</code> in your browser;
                li Default credentials are:
                    ul
                        li Username: <code>"dio"</code>;
                        li Password: <code>"diopw"</code>;
                li Credentials can be changed on the <code>group_vars/kube_cluster.yml</code> file (variables <code>dio_es_user</code> and <code>dio_es_pass</code>).


    p
        | More information available at
        |
        a(href='https://github.com/dsrhaslab/dio/blob/main/dio-pipeline/README.md', target='_blank', style='color: blue;') dio-pipeline.

    .line

    h3 Tracer

    br

    p DIO's tracer can either be installed manually or via Docker.
    br

    h5#dockerTracer > From Docker Image

    br

    p The tracer is available in Docker Hub. To use it, run the following commands.

    ol
        li Pull DIO's tracer image from Docker Hub:
        pre $ docker pull taniaesteves/dio:v1.0.1

        li Run DIO's tracer container:
        pre $ docker run -it --rm --name dio --pid=host --privileged --cap-add=ALL --net=host -v /lib/modules:/lib/modules -v /usr/src:/usr/src -v /sys/kernel/debug/:/sys/kernel/debug/ taniaesteves/dio:v1.0.1 &lt;TARGET_COMMAND&gt;

    br

    h5#dockerTracer > From source code

    br

    ol
        li Install the following dependencies:
        ul
            li GO (v.1.17.4)
            li
                |
                a(href="https://github.com/iovisor/bcc.git", target='_blank', style='color: blue;') BCC
                |  (#1313fd6a5)
        br
        p
            | The following commands can be used to install these dependencies:
            pre $ bash scripts/install_dio_dependencies.sh (go|bcc|all)

        li Build dio-tracer binary:
        pre $ bash scripts/build.sh go

        li Run DIO's tracer:
        pre $ sudo bin/dio-tracer [options] -- &lt;TARGET_COMMAND&gt;

        details
            summary Example
            pre $ sudo bin/dio-tracer --config config.yaml -- ls

    h6 Options:

    ul
        li
            | To change DIO's configuration file, mount a volume for the <code>/usr/share/dio/conf/config.yaml</code> file.<br>
            | Example: <code>-v &lt;path_to_local_config_file&gt;:/usr/share/dio/conf/config.yaml</code>.
        li
            |To export DIO Tracer's files (e.g., tracer logs and statistics), mount a volume for the <code>/dio_data</code> folder.<br>
            | Example: <code>-v /tmp/dio_data:/dio_data</code>

        li To run DIO's correlation path algorithm along with DIO's tracer use the following options:
            ul
                li <code>-e CORRELATE_PATHS=true</code>
                li <code>-e ES_SERVERS=&lt;DIO_ES_URL&gt;:&lt;DIO_ES_PORT&gt;</code>

    p
        | More information available at
        |
        a(href='https://github.com/dsrhaslab/dio/blob/main/dio-tracer/README.md', target='_blank', style='color: blue;') dio-tracer.